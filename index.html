<!-- <!DOCTYPE html>

<html><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta content="IE=5.0000" http-equiv="X-UA-Compatible">
  <meta name="description" content="Falcary's home page"> 
  <link rel="icon" media="(prefers-color-scheme:dark)" href="./assets/imgs/favicon-dark.png" type="image/png" />
  <link rel="icon" media="(prefers-color-scheme:light)" href="./assets/imgs/favicon.png" type="image/png" />
  <link href="./profile.css" rel="stylesheet" type="text/css"> 
  <title>Falcary's Homepage</title> 
  <meta name="GENERATOR" content="MSHTML 11.00.10570.1001">
</head> -->


<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <meta name="description" content="Falcary's homepage">
    <title>Falcary's Homepage</title>
    <link rel="icon" media="(prefers-color-scheme:dark)" href="./assets/imgs/favicon-dark.png" type="image/png" />
    <link rel="icon" media="(prefers-color-scheme:light)" href="./assets/imgs/favicon.png" type="image/png" />
    <link href="./profile.css" rel="stylesheet" type="text/css">
    <meta name="GENERATOR" content="MSHTML 11.00.10570.1001">
    
    <style>
        body {
            font-family: Georgia, serif;
            color: #111;
            width: 900px;
        }

        .profile-pic {
            width: 280px;
            border-radius: 5px; 
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease;
        }

        .profile-pic:hover {
            transform: scale(1.04);
        }

        .top-section {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .contact-box {
            background: #f9f9f9;
            border-radius: 8px;
            padding: 10px 12px;
            display: inline-block;
            margin-top: 0.6em;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.05);
            font-size: 0.95em;
        }

        .contact-box img {
            width: 16px;
            vertical-align: middle;
            margin-right: 6px;
            opacity: 0.9;
        }

        .contact-box a {
            margin-right: 16px;
        }

        .emoji {
            font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, sans-serif;
            font-size: 1.1em;
        }
        .publication-entry {
            display: flex;
            gap: 20px;
            align-items: center;
            background: #fdfdfd;
            padding: 16px 20px; /* âœ… ä¿ç•™è¿™è¡Œï¼Œå»æ‰é‡å¤çš„ padding:12px */
            margin: 20px 0;
            border-radius: 12px;
            border: 1px solid #eee;
            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.03);
        }

        .publication-entry img {
            width: 240px;          /* âœ… æ›´å¤§å›¾å®½ */
            height: 160px;
            object-fit: cover;
            border-radius: 10px;
            flex-shrink: 0;
            margin-left: -4px;     /* âœ… å¾®å¾®é è¿‘å·¦è¾¹ç•Œ */
        }

        .publication-entry div {
            line-height: 1.6;
            flex: 1;               /* âœ… è‡ªåŠ¨æ’‘æ»¡å³ä¾§ */
        }

        .pub-list {
            list-style: none;
            padding-left: 0;
        }
        
        h1,
        h2 {
            color: #263054;
            border-bottom: 1px solid #aaa;
            padding-bottom: 5px;
            margin-top: 20px;
        }
    </style>
</head>


<body> 
  <div id="layout-content" style="margin-top: 25px;">
  <table>
    <tbody>
    <tr>
      <td width="670">
        <div id="toptitle">
        <h1>Chaoran Feng</h1></div>
        <h3><span class="emoji">ğŸ“</span> Master Student</h3>
        <p><a href="https://www.ece.pku.edu.cn/">School of Electric and Computer Engineering</a>
        <br>Peking University,
        <br>Beijing, China
        <br>
        <!-- <br> Email:  
        <a href="mailto:fcr1500583403@gmail.com">fcr1500583403@gmail.com</a>
        <br> -->
        <!-- <br>  -->
        <!-- [<a href="https://scholar.google.com/citations?user=Thyo5v4AAAAJ&hl=en">Google Scholar</a>]&nbsp;&nbsp[<a href="https://github.com/SuperFCR">GitHub</a>] -->
        
        <div class="contact-box">
            <img src="./assets/imgs/envelope.png" alt="Email">
            <a href="mailto:fcr1500583403@gmail.com">fcr1500583403@gmail.com</a>

            <img src="./assets/imgs/google.png" alt="Google Scholar">
            <a href="https://scholar.google.com/citations?user=Thyo5v4AAAAJ&hl=en" target="_blank">Google Scholar</a>

            <img src="./assets/imgs/github.png" alt="GitHub">
            <a href="https://github.com/SuperFCR" target="_blank">GitHub</a>

        </div>
        </p>
      </td>

      <!-- <td>
        <div>
          <img width="270" src="./assets/imgs/bio.jpg" border="0">
        </div>
      </td> -->
      <td>
        <div>
            <img class="profile-pic" src="./assets/imgs/bio.jpg" alt="Profile Picture">
        </div>
      </td>
    </tr>
    <tr></tr></tbody>
  </table>
  <div id="layout-content" style="margin-top: 25px;">


<h2>Education</h2>
  <ul>
    <li>
      [2020-2024] ğŸ‰ I received my B.E. degree from <a href="https://en.dlut.edu.cn/">Dalian University of Technology</a>, awarded the Outstanding Graduate (Top 3%), ranking <b>1<sup>st</sup></b>/85 for three years (2021-2023).
    </li>
    <li>
      [2024-Now] ğŸ’ª I'm pursuing my M.S. degree in ECE, PKU, supervised by <a href="https://yuanli2333.github.io/">Prof. Li Yuan</a> and <a href="https://scholar.google.com/citations?user=fn6hJx0AAAAJ&hl=en">Prof. Yonghong Tian</a>.
    </li>

  </ul>
    
<h2>Biography</h2>
  <p>I am a first-year M.S. student in ECE at Peking University, holding a B.E. degree from Dalian University of Technology. During my undergraduate studies, I achieved a GPA of 3.8/4.0, ranking <b>1<sup>st</sup></b>/85 in both major and overall scores.
      <br><br> ğŸ“Œ My research interests focus on <i>3D Vision</i>, <i> Neuromorphic Vision</i>, and <i>Generative Model</i>.
  </p>


<h2>News</h2>
<ul>
  <li>
    [2025-06] Two papers accepted by <i>ICCV 2025</i>, <a href="https://arxiv.org/pdf/2405.20224 ">"EvaGaussians"</a> and <a href="https://iccv.thecvf.com/virtual/2025/poster/2554">"Tune-Your-Style"</a>.
  </li>
  <li>
    [2025-03] ğŸ”¥ We release <a href="https://arxiv.org/pdf/2503.23162">"NeuralGS"</a>, a novel framework that effectively adopts the neural field representation to encode the attributes of 3D Gaussians with multiple tiny MLPs.
  </li>
  <li>
    [2025-01] ğŸ”¥ We release <a href="https://arxiv.org/pdf/2501.02807">"AE-NeRF"</a>, a novel framework for 3D reconstruction using event streams under noisy poses and in unbounded larger scenes.
  </li>
  <li>
    [2024-12] Two papers accepted by <i>AAAI 2025</i>.
  </li>
  <li>
    [2024-05] ğŸ”¥ We release <a href="https://arxiv.org/pdf/2405.20224 ">"EvaGaussians"</a>, a first approach that reconstruct sharp static 3D scenes with sparse RGB frames and event streams.
  </li>
  <li>
    [2023-09] One papers accepted by <i>NeurIPS 2023</i>.
  </li>
</ul>



<h2>Selected Projects</h2>
* Equal Contribution &nbsp;&nbsp # Project Lead
<!-- <br><br><tr><td><b><font color="#001F3F">&spades; 3D Reconstruction & Generative Model </font></b></td></tr> -->
<br><br><tr><td><b><font color="#001F3F">&spades; 3D Reconstruction & Generative Model </font></b></td></tr>
<ul class="pub-list">
    <li>
        <div class="publication-entry">
            <img src="./assets/pipelines/Pipeline_tune_your_style.png" alt="Tune-Your-Style">
            <div>
                <b>ğŸ¨ Tune-Your-Style: Intensity-tunable 3D Style Transfer with Gaussian Splatting</b><br>
                <span style="color: #777;">Yian Zhao, Rushi Ye, Ruochong Zheng, Zesen Cheng, <u><b>Chaoran Feng*</b></u>, Jiashu Yang, Pengchong Qiao, Chang Liu, Jie Chenâ€ </span><br>
                <i style="color: #b70505c0;">A novel style transfer framework with 3D Gaussian Splatting.</i><br>
                <i><b>ICCV 2025</b></i> &nbsp; [<a href="https://iccv.thecvf.com/virtual/2025/poster/2554">Paper</a>]
            </div>
        </div>
    </li>
</ul>

<ul class="pub-list">

  <li>
    <div class="publication-entry">
      <img src="./assets/pipelines/Pipeline_cycle3d.png" alt="Cycle3D">
      <div>
        <b>ğŸ”¥ Cycle3D: High-quality and Consistent Image-to-3D Generation via Generation-Reconstruction Cycle</b><br>
        <span style="color: #777;">Zhenyu Tang*, Junwu Zhang*, Xinhua Cheng, Wangbo Yu, <u><b>Chaoran Feng</b></u>, Yatian Pang, Bin Lin, Li Yuanâ€ </span><br>
        <i style="color: #b70505c0;">The project is about 3D generation using a generation-reconstruction cycle for a unified diffusion process.</i><br>
        <i><b>AAAI 2025</b></i> &nbsp;
        [<a href="https://arxiv.org/pdf/2407.19548">Paper</a>]
        [<a href="https://github.com/PKU-YuanGroup/Cycle3D">Code ğŸŒŸ200+</a>]
      </div>
    </div>
  </li>

  <li>
    <div class="publication-entry">
      <img src="./assets/pipelines/Pipeline_neuralgs.png" alt="NeuralGS">
      <div>
        <b>ğŸŒ€ NeuralGS: Bridging Neural Fields and 3D Gaussian Splatting for Compact 3D Representations</b><br>
        <span style="color: #777;">Zhenyu Tang*, <u><b>Chaoran Feng*</b></u>, Xinhua Cheng, Wangbo Yu, Junwu Zhang, Yuan Liuâ€ , Xiaoxiao Long, Wenping Wang, Li Yuanâ€ </span><br>
        <i style="color: #b70505c0;">A novel framework using neural fields to encode 3D Gaussians with compact MLPs for large-scale scenes.</i><br>
        <i><b>Arxiv 2025</b></i> &nbsp;
        [<a href="https://arxiv.org/pdf/2503.23162">Paper</a>]
        [<a href="https://github.com/PKU-YuanGroup/NeuralGS">Code ğŸŒŸ150+</a>]
      </div>
    </div>
  </li>

  <li>
    <div class="publication-entry">
      <img src="./assets/pipelines/Pipeline_d2gs.png" alt="D2GS">
      <div>
        <b>ğŸ“¦ D<sup>2</sup>GS: Deblurring Deformable 3D Gaussian Splatting for Motion-Blurred Causal Videos</b><br>
        <span style="color: #777;"><u><b>Chaoran Feng</b></u>, Jianbin Zhao, Wangbo Yu, Zhenyu Tang, Yuchen Li, Li Yuanâ€ , and Yonghong Tianâ€ </span><br>
        <i style="color: #b70505c0;">A novel framework to reconstruct high-quality 4D scenes from blurry videos.</i><br>
        <i><b>Notes: Paper is under review by T-CSVT!</b></i> &nbsp;
        [<a href="./assets/files/D2GS_Deblurring_Deformable_3D_Gaussian_Splatting_for_Motion-Blurred_Causal Vide.pdf">Paper</a>]
      </div>
    </div>
  </li>

  <li>
    <div class="publication-entry">
      <img src="./assets/pipelines/Pipeline_nofa++.png" alt="NOFA++">
      <div>
        <b>ğŸ‘¤ NOFA++: Tuning-free NeRF-based One-shot Facial Avatar Reconstruction</b><br>
        <span style="color: #777;">Wangbo Yu, <u><b>Chaoran Feng</b></u>, Yanbo Fanâ€ , Yong Zhang, Xuan Wang, Fei Yin, Yunpeng Bai, Baoyuan Wu, Yan-Pei Cao, Li Yuanâ€ , and Yonghong Tianâ€ </span><br>
        <i style="color: #b70505c0;">One-shot 3D facial avatar reconstruction with high fidelity and dynamic reenactment from a single image.</i><br>
        <i><b>Notes: Paper is under review by T-PAMI!</b></i> &nbsp;
        [<a href="./assets/files/20241015-PAMI_NOFA____NeRF_based_One_shot_Facial_Avatar_Reconstruction_and_beyond.pdf">Paper</a>]
      </div>
    </div>
  </li>

</ul>


<br>
<tr><td><b><font color="#001F3F">&spades; Neuromorphic Vision </font></b></td></tr>
<ul class="pub-list">
  <li>
    <div class="publication-entry">
      <img src="./assets/pipelines/Pipeline_ae_nerf.png" alt="AE-NeRF">
      <div>
        <b>âš¡ AE-NeRF: Augmenting Event-Based Neural Radiance Fields for Non-ideal Conditions and Larger Scenes</b><br>
        <span style="color: #777;"><u><b>Chaoran Feng</b></u>, Wangbo Yu, Xinhua Cheng, Zhenyu Tang, Junwu Zhang, Li Yuanâ€ , Yonghong Tianâ€ </span><br>
        <i style="color: #b70505c0;">3D reconstruction with event streams under noisy poses and unbounded scenes.</i><br>
        <i><b>AAAI 2025</b></i> &nbsp;
        [<a href="https://arxiv.org/pdf/2501.02807">Paper</a>]
        [<a href="https://drexubery.github.io/EvaGaussians/">Code</a>]
      </div>
    </div>
  </li>

  <li>
    <div class="publication-entry">
      <img src="./assets/pipelines/Pipeline_evagaussian.png" alt="EvaGaussians">
      <div>
        <b>âœ¨ EvaGaussians: Event Assisted Gaussian Splatting from Blurry Images</b><br>
        <span style="color: #777;">Wangbo Yu*, <u><b>Chaoran Feng*</b></u>, Jiye Tang, Jiashu Yang, Zhenyu Tang, Xu Jia, Yuchao Yang, Li Yuanâ€ , Yonghong Tianâ€ </span><br>
        <i style="color: #b70505c0;">Event-assisted 3D reconstruction from blurry images with noisy poses and dynamic scenes.</i><br>
        <i><b>ICCV 2025</b></i> &nbsp;
        [<a href="https://arxiv.org/abs/2405.20224">Paper</a>]
        [<a href="https://github.com/SuperFCR">Code ğŸŒŸ50+</a>]
      </div>
    </div>
  </li>

</ul>


<!-- <ul>
  <li>
    <div style="margin-top: 30px;"><b>EICIL:Joint Excitatory Inhibitory Cycle Iteration Learning for Deep Spiking Neural Networks</b></div>
      <div style="margin-top: 5px;"><a style="color: #777;">Zihang Shao, Xuanye Fang, Yaxin Li, <u><b>Chaoran Feng</b></u>, Jiangrong Shen, Qi Xuâ€ 
      <div style="margin-top: 5px;"><a style="color: #b70505c0;"><i>The project is about 3d reconstruction with event stream in noisy poses and unbounded larger scenes.</i></a></div>
      <div style="margin-top: 5px;"><i><b>NeurIPS 2023</b></i><br></div>
      <div style="margin-top: 5px;">[<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/65e876f6a98c6799d0b3145966dd73e2-Paper-Conference.pdf">Paper</a>]</div>
    </td>
  </li>
</ul> -->


<h2>Award</h2>
<ul>
  <li>
    [2024-06]ğŸ“ Outstanding Graduate, Dalian University of Technology (Top <b>3%</b>)
  </li>


  <li>
    [2023-05]ğŸ† 1<sup>st</sup> Prize in the China Robotics and Artificial Intelligence Competition (Ranked <b>1<sup>st</sup></b>/100+)
  </li>

  <li>
    [2022-10]ğŸŒŸ Qubochuan Scholarship, highest scholarship of DUT, awarded to only 10 recipients each year
  </li>
  <li>
    [2021,2022,2023]ğŸŒŸ Nation Scholarship, three times, Dalian University of Technology
  </li>
  <li>
    [2021,2022,2023]ğŸŒŸ Academic Excellence Scholarship (First Class) (Ranked <b>1<sup>st</sup></b>/85), Dalian University of Technology
  </li>
</ul>


<h2>Professional Activities </h2>
<ul>
  <li>
  Conference Reviewer: ICLR[25], CVPR[25], ICCV[25], NeurIPS[24-25], AAAI[25-26], IJCAI[25], ACM MM[25]; 
  </li>
  <li>
  Jounal Reviewer: TCSVT; 
  </li>
</ul>

<ul>
</ul>

</td>
</tr>
</table>

<a href="https://clustrmaps.com/site/1c5bo"  title="Visit tracker">
  <img src="//www.clustrmaps.com/map_v2.png?d=BRf4_qJelQm7X4ukCxJuzTHr88doqXYrA5-S7H0IEWA&cl=ffffff" />
</a>


</body>

</div>
</div>

</body>
</html>
